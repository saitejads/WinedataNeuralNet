{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network on Winedata using Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This a simple neural network classification on the winedata, I have kept it simple, not much of the data preprocessing and visualization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frankly speaking, this dataset is not a worth of Neural Networks, but I chose this dataset, since this is my first attempt on NN's and i want to keep it simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is available at 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The Column names and other details are at 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['Class','Alcohol','Malic acid','Ash','Alcalinity of ash','Magnesium','Total phenols','Flavanoids','Nonflavanoid phenols','Proanthocyanins','Color intensity','Hue','dilute','Proline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data',names = colnames,index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snapshot of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>dilute</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0      1    14.23        1.71  2.43               15.6        127   \n",
       "1      1    13.20        1.78  2.14               11.2        100   \n",
       "2      1    13.16        2.36  2.67               18.6        101   \n",
       "3      1    14.37        1.95  2.50               16.8        113   \n",
       "4      1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  dilute  Proline  \n",
       "0             5.64  1.04    3.92     1065  \n",
       "1             4.38  1.05    3.40     1050  \n",
       "2             5.68  1.03    3.17     1185  \n",
       "3             7.80  0.86    3.45     1480  \n",
       "4             4.32  1.04    2.93      735  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if it has any null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class                   0\n",
       "Alcohol                 0\n",
       "Malic acid              0\n",
       "Ash                     0\n",
       "Alcalinity of ash       0\n",
       "Magnesium               0\n",
       "Total phenols           0\n",
       "Flavanoids              0\n",
       "Nonflavanoid phenols    0\n",
       "Proanthocyanins         0\n",
       "Color intensity         0\n",
       "Hue                     0\n",
       "dilute                  0\n",
       "Proline                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 178 entries, 0 to 177\n",
      "Data columns (total 14 columns):\n",
      "Class                   178 non-null int64\n",
      "Alcohol                 178 non-null float64\n",
      "Malic acid              178 non-null float64\n",
      "Ash                     178 non-null float64\n",
      "Alcalinity of ash       178 non-null float64\n",
      "Magnesium               178 non-null int64\n",
      "Total phenols           178 non-null float64\n",
      "Flavanoids              178 non-null float64\n",
      "Nonflavanoid phenols    178 non-null float64\n",
      "Proanthocyanins         178 non-null float64\n",
      "Color intensity         178 non-null float64\n",
      "Hue                     178 non-null float64\n",
      "dilute                  178 non-null float64\n",
      "Proline                 178 non-null int64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 19.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know about the class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    71\n",
       "1    59\n",
       "3    48\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check which columns are correlated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>dilute</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.328222</td>\n",
       "      <td>0.437776</td>\n",
       "      <td>-0.049643</td>\n",
       "      <td>0.517859</td>\n",
       "      <td>-0.209179</td>\n",
       "      <td>-0.719163</td>\n",
       "      <td>-0.847498</td>\n",
       "      <td>0.489109</td>\n",
       "      <td>-0.499130</td>\n",
       "      <td>0.265668</td>\n",
       "      <td>-0.617369</td>\n",
       "      <td>-0.788230</td>\n",
       "      <td>-0.633717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcohol</th>\n",
       "      <td>-0.328222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094397</td>\n",
       "      <td>0.211545</td>\n",
       "      <td>-0.310235</td>\n",
       "      <td>0.270798</td>\n",
       "      <td>0.289101</td>\n",
       "      <td>0.236815</td>\n",
       "      <td>-0.155929</td>\n",
       "      <td>0.136698</td>\n",
       "      <td>0.546364</td>\n",
       "      <td>-0.071747</td>\n",
       "      <td>0.072343</td>\n",
       "      <td>0.643720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malic acid</th>\n",
       "      <td>0.437776</td>\n",
       "      <td>0.094397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.164045</td>\n",
       "      <td>0.288500</td>\n",
       "      <td>-0.054575</td>\n",
       "      <td>-0.335167</td>\n",
       "      <td>-0.411007</td>\n",
       "      <td>0.292977</td>\n",
       "      <td>-0.220746</td>\n",
       "      <td>0.248985</td>\n",
       "      <td>-0.561296</td>\n",
       "      <td>-0.368710</td>\n",
       "      <td>-0.192011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ash</th>\n",
       "      <td>-0.049643</td>\n",
       "      <td>0.211545</td>\n",
       "      <td>0.164045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.443367</td>\n",
       "      <td>0.286587</td>\n",
       "      <td>0.128980</td>\n",
       "      <td>0.115077</td>\n",
       "      <td>0.186230</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>0.258887</td>\n",
       "      <td>-0.074667</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>0.223626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <td>0.517859</td>\n",
       "      <td>-0.310235</td>\n",
       "      <td>0.288500</td>\n",
       "      <td>0.443367</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-0.321113</td>\n",
       "      <td>-0.351370</td>\n",
       "      <td>0.361922</td>\n",
       "      <td>-0.197327</td>\n",
       "      <td>0.018732</td>\n",
       "      <td>-0.273955</td>\n",
       "      <td>-0.276769</td>\n",
       "      <td>-0.440597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Magnesium</th>\n",
       "      <td>-0.209179</td>\n",
       "      <td>0.270798</td>\n",
       "      <td>-0.054575</td>\n",
       "      <td>0.286587</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214401</td>\n",
       "      <td>0.195784</td>\n",
       "      <td>-0.256294</td>\n",
       "      <td>0.236441</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>0.055398</td>\n",
       "      <td>0.066004</td>\n",
       "      <td>0.393351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total phenols</th>\n",
       "      <td>-0.719163</td>\n",
       "      <td>0.289101</td>\n",
       "      <td>-0.335167</td>\n",
       "      <td>0.128980</td>\n",
       "      <td>-0.321113</td>\n",
       "      <td>0.214401</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.864564</td>\n",
       "      <td>-0.449935</td>\n",
       "      <td>0.612413</td>\n",
       "      <td>-0.055136</td>\n",
       "      <td>0.433681</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>0.498115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flavanoids</th>\n",
       "      <td>-0.847498</td>\n",
       "      <td>0.236815</td>\n",
       "      <td>-0.411007</td>\n",
       "      <td>0.115077</td>\n",
       "      <td>-0.351370</td>\n",
       "      <td>0.195784</td>\n",
       "      <td>0.864564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.537900</td>\n",
       "      <td>0.652692</td>\n",
       "      <td>-0.172379</td>\n",
       "      <td>0.543479</td>\n",
       "      <td>0.787194</td>\n",
       "      <td>0.494193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <td>0.489109</td>\n",
       "      <td>-0.155929</td>\n",
       "      <td>0.292977</td>\n",
       "      <td>0.186230</td>\n",
       "      <td>0.361922</td>\n",
       "      <td>-0.256294</td>\n",
       "      <td>-0.449935</td>\n",
       "      <td>-0.537900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.365845</td>\n",
       "      <td>0.139057</td>\n",
       "      <td>-0.262640</td>\n",
       "      <td>-0.503270</td>\n",
       "      <td>-0.311385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <td>-0.499130</td>\n",
       "      <td>0.136698</td>\n",
       "      <td>-0.220746</td>\n",
       "      <td>0.009652</td>\n",
       "      <td>-0.197327</td>\n",
       "      <td>0.236441</td>\n",
       "      <td>0.612413</td>\n",
       "      <td>0.652692</td>\n",
       "      <td>-0.365845</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025250</td>\n",
       "      <td>0.295544</td>\n",
       "      <td>0.519067</td>\n",
       "      <td>0.330417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color intensity</th>\n",
       "      <td>0.265668</td>\n",
       "      <td>0.546364</td>\n",
       "      <td>0.248985</td>\n",
       "      <td>0.258887</td>\n",
       "      <td>0.018732</td>\n",
       "      <td>0.199950</td>\n",
       "      <td>-0.055136</td>\n",
       "      <td>-0.172379</td>\n",
       "      <td>0.139057</td>\n",
       "      <td>-0.025250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.521813</td>\n",
       "      <td>-0.428815</td>\n",
       "      <td>0.316100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hue</th>\n",
       "      <td>-0.617369</td>\n",
       "      <td>-0.071747</td>\n",
       "      <td>-0.561296</td>\n",
       "      <td>-0.074667</td>\n",
       "      <td>-0.273955</td>\n",
       "      <td>0.055398</td>\n",
       "      <td>0.433681</td>\n",
       "      <td>0.543479</td>\n",
       "      <td>-0.262640</td>\n",
       "      <td>0.295544</td>\n",
       "      <td>-0.521813</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565468</td>\n",
       "      <td>0.236183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dilute</th>\n",
       "      <td>-0.788230</td>\n",
       "      <td>0.072343</td>\n",
       "      <td>-0.368710</td>\n",
       "      <td>0.003911</td>\n",
       "      <td>-0.276769</td>\n",
       "      <td>0.066004</td>\n",
       "      <td>0.699949</td>\n",
       "      <td>0.787194</td>\n",
       "      <td>-0.503270</td>\n",
       "      <td>0.519067</td>\n",
       "      <td>-0.428815</td>\n",
       "      <td>0.565468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.312761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Proline</th>\n",
       "      <td>-0.633717</td>\n",
       "      <td>0.643720</td>\n",
       "      <td>-0.192011</td>\n",
       "      <td>0.223626</td>\n",
       "      <td>-0.440597</td>\n",
       "      <td>0.393351</td>\n",
       "      <td>0.498115</td>\n",
       "      <td>0.494193</td>\n",
       "      <td>-0.311385</td>\n",
       "      <td>0.330417</td>\n",
       "      <td>0.316100</td>\n",
       "      <td>0.236183</td>\n",
       "      <td>0.312761</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Class   Alcohol  Malic acid       Ash  \\\n",
       "Class                 1.000000 -0.328222    0.437776 -0.049643   \n",
       "Alcohol              -0.328222  1.000000    0.094397  0.211545   \n",
       "Malic acid            0.437776  0.094397    1.000000  0.164045   \n",
       "Ash                  -0.049643  0.211545    0.164045  1.000000   \n",
       "Alcalinity of ash     0.517859 -0.310235    0.288500  0.443367   \n",
       "Magnesium            -0.209179  0.270798   -0.054575  0.286587   \n",
       "Total phenols        -0.719163  0.289101   -0.335167  0.128980   \n",
       "Flavanoids           -0.847498  0.236815   -0.411007  0.115077   \n",
       "Nonflavanoid phenols  0.489109 -0.155929    0.292977  0.186230   \n",
       "Proanthocyanins      -0.499130  0.136698   -0.220746  0.009652   \n",
       "Color intensity       0.265668  0.546364    0.248985  0.258887   \n",
       "Hue                  -0.617369 -0.071747   -0.561296 -0.074667   \n",
       "dilute               -0.788230  0.072343   -0.368710  0.003911   \n",
       "Proline              -0.633717  0.643720   -0.192011  0.223626   \n",
       "\n",
       "                      Alcalinity of ash  Magnesium  Total phenols  Flavanoids  \\\n",
       "Class                          0.517859  -0.209179      -0.719163   -0.847498   \n",
       "Alcohol                       -0.310235   0.270798       0.289101    0.236815   \n",
       "Malic acid                     0.288500  -0.054575      -0.335167   -0.411007   \n",
       "Ash                            0.443367   0.286587       0.128980    0.115077   \n",
       "Alcalinity of ash              1.000000  -0.083333      -0.321113   -0.351370   \n",
       "Magnesium                     -0.083333   1.000000       0.214401    0.195784   \n",
       "Total phenols                 -0.321113   0.214401       1.000000    0.864564   \n",
       "Flavanoids                    -0.351370   0.195784       0.864564    1.000000   \n",
       "Nonflavanoid phenols           0.361922  -0.256294      -0.449935   -0.537900   \n",
       "Proanthocyanins               -0.197327   0.236441       0.612413    0.652692   \n",
       "Color intensity                0.018732   0.199950      -0.055136   -0.172379   \n",
       "Hue                           -0.273955   0.055398       0.433681    0.543479   \n",
       "dilute                        -0.276769   0.066004       0.699949    0.787194   \n",
       "Proline                       -0.440597   0.393351       0.498115    0.494193   \n",
       "\n",
       "                      Nonflavanoid phenols  Proanthocyanins  Color intensity  \\\n",
       "Class                             0.489109        -0.499130         0.265668   \n",
       "Alcohol                          -0.155929         0.136698         0.546364   \n",
       "Malic acid                        0.292977        -0.220746         0.248985   \n",
       "Ash                               0.186230         0.009652         0.258887   \n",
       "Alcalinity of ash                 0.361922        -0.197327         0.018732   \n",
       "Magnesium                        -0.256294         0.236441         0.199950   \n",
       "Total phenols                    -0.449935         0.612413        -0.055136   \n",
       "Flavanoids                       -0.537900         0.652692        -0.172379   \n",
       "Nonflavanoid phenols              1.000000        -0.365845         0.139057   \n",
       "Proanthocyanins                  -0.365845         1.000000        -0.025250   \n",
       "Color intensity                   0.139057        -0.025250         1.000000   \n",
       "Hue                              -0.262640         0.295544        -0.521813   \n",
       "dilute                           -0.503270         0.519067        -0.428815   \n",
       "Proline                          -0.311385         0.330417         0.316100   \n",
       "\n",
       "                           Hue    dilute   Proline  \n",
       "Class                -0.617369 -0.788230 -0.633717  \n",
       "Alcohol              -0.071747  0.072343  0.643720  \n",
       "Malic acid           -0.561296 -0.368710 -0.192011  \n",
       "Ash                  -0.074667  0.003911  0.223626  \n",
       "Alcalinity of ash    -0.273955 -0.276769 -0.440597  \n",
       "Magnesium             0.055398  0.066004  0.393351  \n",
       "Total phenols         0.433681  0.699949  0.498115  \n",
       "Flavanoids            0.543479  0.787194  0.494193  \n",
       "Nonflavanoid phenols -0.262640 -0.503270 -0.311385  \n",
       "Proanthocyanins       0.295544  0.519067  0.330417  \n",
       "Color intensity      -0.521813 -0.428815  0.316100  \n",
       "Hue                   1.000000  0.565468  0.236183  \n",
       "dilute                0.565468  1.000000  0.312761  \n",
       "Proline               0.236183  0.312761  1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above Ash has very very low correlation in detecting the class, so it can be removed to improve our model. I'm dropping the ash columns in the following code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We convert the Class labels into the Onehot format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now only take the labels into to new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.loc[:,['Class_1','Class_2','Class_3']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Neural Nets the data should be in numpy arrays, so convert them,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now collect the features dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['Class_1','Class_2','Class_3','Ash'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the feature dataframe to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(labels))\n",
    "print(type(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shape of the arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 3)\n",
      "(178, 12)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into the training and testing sets, We have just 178 columns, which is a very very very small data for NN's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y = train_test_split(features,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the shapes of the split datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 12) (133, 3) (45, 12) (45, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape,train_y.shape,test_x.shape,test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks good, so lets go further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks perform better if the data is scaled between (0,1). So, lets do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler(feature_range = (0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = scale.fit_transform(train_x)\n",
    "test_x = scale.fit_transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snapshot of the features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47894737 0.48472505 0.58762887 0.39130435 0.23103448 0.05485232\n",
      " 0.88679245 0.17350158 0.3668942  0.31707317 0.30769231 0.20143885]\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Neural Network part begins here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[None,12]) # Since we have 12 features as input\n",
    "y = tf.placeholder(tf.float32,[None,3])  # Since we have 3 outut labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create our model with 2 hidden layers with 80 and 50 nodes respectively.\n",
    "It was suggested(by online tutor) to use xavier_initializer for weights and zeros initializer for biases, but not mandatory.( I have been used to it, so i continued with this)\n",
    "I have also ran the model with random weights, they eventually optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights1 = tf.get_variable(\"weights1\",shape=[12,80],initializer = tf.contrib.layers.xavier_initializer())\n",
    "biases1 = tf.get_variable(\"biases1\",shape = [80],initializer = tf.zeros_initializer)\n",
    "layer1out = tf.nn.relu(tf.matmul(X,weights1)+biases1)\n",
    "\n",
    "weights2 = tf.get_variable(\"weights2\",shape=[80,50],initializer = tf.contrib.layers.xavier_initializer())\n",
    "biases2 = tf.get_variable(\"biases2\",shape = [50],initializer = tf.zeros_initializer)\n",
    "layer2out = tf.nn.relu(tf.matmul(layer1out,weights2)+biases2)\n",
    "\n",
    "weights3 = tf.get_variable(\"weights3\",shape=[50,3],initializer = tf.contrib.layers.xavier_initializer())\n",
    "biases3 = tf.get_variable(\"biases3\",shape = [3],initializer = tf.zeros_initializer)\n",
    "prediction =tf.matmul(layer2out,weights3)+biases3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the loss function, softmax_cross_entropy_with_logits_v2 is suggested over softmax_cross_entropy_with_logits because of label backpropagation, and then optimize the loss function. I have choose the learning rate as 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm expecting that everyone has an idea about the below process so I'm not going to elaborate much on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matches is a list(tensor) which takes 1, if the index of largest element in prediction and y are equal and 0 it the indices are not equal.\n",
    "Accuracy is calculated by taking the mean of those matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -- Cost 1.1028452\n",
      "Accuracy on the test set -> 0.46666667\n",
      "Epoch 50 -- Cost 0.39478666\n",
      "Accuracy on the test set -> 0.93333334\n",
      "Epoch 100 -- Cost 0.094202965\n",
      "Accuracy on the test set -> 0.93333334\n",
      "Epoch 150 -- Cost 0.04765493\n",
      "Accuracy on the test set -> 0.93333334\n",
      "Epoch 200 -- Cost 0.028836355\n",
      "Accuracy on the test set -> 0.95555556\n",
      "FINISHED !!!\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(201):\n",
    "        opt,costval = sess.run([optimizer,cost],feed_dict = {X:train_x,y:train_y})\n",
    "        matches = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(matches, 'float'))\n",
    "        acc.append(accuracy.eval({X:test_x,y:test_y}))\n",
    "        if(epoch % 50 == 0):\n",
    "            print(\"Epoch\", epoch, \"--\" , \"Cost\",costval)\n",
    "            print(\"Accuracy on the test set ->\",accuracy.eval({X:test_x,y:test_y}))\n",
    "    print(\"FINISHED !!!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that they cost(loss) is reducing and the Accuracy is increasing, which shows that our model is training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets plot the Accuracy over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Epochs')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x18028dcde80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(acc)\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph of the accuracy over training steps(Epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last words.\n",
    "This is not the best dataset for the neural networks. I would suggest something huge, like really huge.\n",
    "The accuracy of 97.778 might not the best we can get.We can tune the model more by changing the epochs, learning rate.\n",
    "There is no much significane of this kernel, better accuracies might be achieved by using sklearn's logisticregression etc.This is just for my understanding of the neural networks.\n",
    "Thankyou!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
